{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b93f82b-7570-48f2-afee-75a43f517774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 15:41:46,291 - INFO - Iniciando Extração de dados do INMET para estação: A701\n",
      "2025-09-29 15:41:46,491 - ERROR - Erro na extração do INMET: 404 Client Error: Not Found for url: https://apitempo.inmet.gov.br/dados/horarios/A701. Usando simulação para continuar o ETL.\n",
      "2025-09-29 15:41:46,504 - INFO - Extração do INMET concluída. 720 registros encontrados (reais ou simulados).\n",
      "2025-09-29 15:41:46,505 - INFO - Extração de ONS exige Web Scraping ou download manual de arquivos.\n",
      "2025-09-29 15:41:46,506 - WARNING - Usando dados fictícios de ONS para simulação de Big Data.\n",
      "2025-09-29 15:41:46,510 - INFO - Extração de CCEE exige Web Scraping ou download manual de arquivos.\n",
      "2025-09-29 15:41:46,511 - WARNING - Usando dados fictícios de CCEE para simulação de Big Data.\n",
      "2025-09-29 15:41:46,513 - INFO - Iniciando Transformação e Engenharia de Features.\n",
      "2025-09-29 15:41:46,527 - INFO - Dados do INMET tratados.\n",
      "2025-09-29 15:41:46,535 - INFO - Transformação concluída. Dataset final (Big Data) com 720 linhas.\n",
      "2025-09-29 15:41:46,547 - INFO - Dados carregados para CSV: dados_projeto_hpo\\dados_hpo_integrados_20250929.csv\n",
      "2025-09-29 15:41:46,547 - INFO - Simulação de Carga concluída. Pronto para Modelagem/Deploy (TensorFlow/PyTorch).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Amostra do Dataset Integrado (Big Data) ---\n",
      "            timestamp  carga_mw_subsistema  frequencia_hz  geracao_eolica_mw  \\\n",
      "0 2025-08-30 16:00:00                25000          60.00                500   \n",
      "1 2025-08-30 17:00:00                25001          60.01                501   \n",
      "2 2025-08-30 18:00:00                25002          60.02                502   \n",
      "3 2025-08-30 19:00:00                25003          60.03                503   \n",
      "4 2025-08-30 20:00:00                25004          60.04                504   \n",
      "\n",
      "   restricao_vazao  CHUVA  TEMP_BULB_SECO  carga_lag_24h  alerta_intermitente  \n",
      "0                1    1.0            26.0            NaN                    0  \n",
      "1                0    2.0            27.0            NaN                    0  \n",
      "2                0    0.0            28.0            NaN                    0  \n",
      "3                0    1.0            29.0            NaN                    0  \n",
      "4                0    2.0            20.0            NaN                    0  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "# Configuração básica de logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- 1. CONFIGURAÇÕES E PARÂMETROS ---\n",
    "CODIGO_ESTACAO_INMET = \"A701\"\n",
    "DATA_FIM = datetime.now().replace(minute=0, second=0, microsecond=0) # Alinhando para hora cheia\n",
    "DATA_INICIO = DATA_FIM - timedelta(days=30) \n",
    "\n",
    "OUTPUT_DIR = \"dados_projeto_hpo\"\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "# --- 2. EXTRAÇÃO (E) ---\n",
    "\n",
    "def extrair_dados_inmet(codigo_estacao: str, data_inicio: datetime, data_fim: datetime) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extrai dados do INMET. Em caso de falha da API real (404),\n",
    "    retorna um DataFrame simulado com as colunas esperadas.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Iniciando Extração de dados do INMET para estação: {codigo_estacao}\")\n",
    "    \n",
    "    # URL da API do INMET (Endpoint conceitual)\n",
    "    URL_API = f\"https://apitempo.inmet.gov.br/dados/horarios/{codigo_estacao}\" \n",
    "    dados = []\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(URL_API, timeout=15)\n",
    "        response.raise_for_status() \n",
    "        dados = response.json()\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Erro na extração do INMET: {e}. Usando simulação para continuar o ETL.\")\n",
    "        \n",
    "        # --- CORREÇÃO APLICADA AQUI ---\n",
    "        # Garantindo que os dados simulados tenham as CHAVES/COLUNAS que a função 'transformar_dados' espera.\n",
    "        horas = pd.date_range(end=DATA_FIM, periods=720, freq='h')\n",
    "        dados = []\n",
    "        for dt in horas:\n",
    "             # Simulando o formato de saída que a API real usaria (para ser tratado na Transformação)\n",
    "             dados.append({\n",
    "                 \"DT_MEDICAO\": dt.strftime(\"%Y-%m-%d\"),\n",
    "                 \"HR_MEDICAO\": dt.strftime(\"%H%M\"), # Exemplo: 1500\n",
    "                 \"CHUVA\": dt.hour % 3,             # Simulação de chuva\n",
    "                 \"TEMP_BULB_SECO\": 20.0 + (dt.hour % 10) # Simulação de temperatura\n",
    "             })\n",
    "\n",
    "    df = pd.DataFrame(dados)\n",
    "    logging.info(f\"Extração do INMET concluída. {len(df)} registros encontrados (reais ou simulados).\")\n",
    "    return df\n",
    "\n",
    "def extrair_dados_ons_ccee(fonte: str) -> pd.DataFrame:\n",
    "    \"\"\"Placeholder para extração de ONS/CCEE (Geração e Carga), agora usando 'h'.\"\"\"\n",
    "    logging.info(f\"Extração de {fonte} exige Web Scraping ou download manual de arquivos.\")\n",
    "    logging.warning(f\"Usando dados fictícios de {fonte} para simulação de Big Data.\")\n",
    "    \n",
    "    # Corrigindo 'H' deprecated para 'h'\n",
    "    datas = pd.date_range(end=DATA_FIM, periods=720, freq='h') \n",
    "    if fonte == 'ONS':\n",
    "        return pd.DataFrame({\n",
    "            'timestamp': datas,\n",
    "            'carga_mw_subsistema': [25000 + i % 1000 for i in range(len(datas))],\n",
    "            'frequencia_hz': [60.0 + (i % 5) / 100 for i in range(len(datas))]\n",
    "        })\n",
    "    else: \n",
    "        return pd.DataFrame({\n",
    "            'timestamp': datas,\n",
    "            'geracao_eolica_mw': [500 + i % 500 for i in range(len(datas))],\n",
    "            'restricao_vazao': [1 if i % 100 == 0 else 0 for i in range(len(datas))]\n",
    "        })\n",
    "\n",
    "# --- 3. TRANSFORMAÇÃO (T) ---\n",
    "\n",
    "def transformar_dados(df_inmet: pd.DataFrame, df_ons: pd.DataFrame, df_ccee: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Realiza a limpeza, unificação e Engenharia de Features.\"\"\"\n",
    "    logging.info(\"Iniciando Transformação e Engenharia de Features.\")\n",
    "\n",
    "    # 3.1. Tratamento e Unificação do INMET\n",
    "    # A lógica aqui espera CHAVES da API real ou da SIMULAÇÃO corrigida.\n",
    "    df_inmet['timestamp'] = pd.to_datetime(\n",
    "        df_inmet['DT_MEDICAO'] + ' ' + df_inmet['HR_MEDICAO'].str.slice(0, 2) + ':00:00',\n",
    "        format='%Y-%m-%d %H:%M:%S', errors='coerce'\n",
    "    )\n",
    "    \n",
    "    # Assegurando que as colunas críticas existam e tratando NaNs\n",
    "    colunas_inmet = ['timestamp', 'CHUVA', 'TEMP_BULB_SECO']\n",
    "    df_inmet = df_inmet[colunas_inmet].dropna().set_index('timestamp')\n",
    "    df_inmet = df_inmet.astype({'CHUVA': 'float64', 'TEMP_BULB_SECO': 'float64'})\n",
    "    logging.info(\"Dados do INMET tratados.\")\n",
    "\n",
    "    # 3.2. Unificação (Big Data: Mesclagem de Fontes)\n",
    "    df_final = pd.merge(df_ons.set_index('timestamp'), df_ccee.set_index('timestamp'),\n",
    "                        left_index=True, right_index=True, how='inner')\n",
    "    df_final = pd.merge(df_final, df_inmet, left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    # 3.3. Engenharia de Features\n",
    "    df_final['carga_lag_24h'] = df_final['carga_mw_subsistema'].shift(24) \n",
    "    df_final['alerta_intermitente'] = (df_final['geracao_eolica_mw'] > 800).astype(int) \n",
    "\n",
    "    logging.info(f\"Transformação concluída. Dataset final (Big Data) com {len(df_final)} linhas.\")\n",
    "    return df_final.reset_index()\n",
    "\n",
    "# --- 4. CARGA (L) ---\n",
    "\n",
    "def carregar_dados(df_final: pd.DataFrame, nome_arquivo: str):\n",
    "    \"\"\"Carrega os dados tratados para um arquivo CSV e simula carga em um BD.\"\"\"\n",
    "    caminho_csv = os.path.join(OUTPUT_DIR, nome_arquivo)\n",
    "    df_final.to_csv(caminho_csv, index=False)\n",
    "    logging.info(f\"Dados carregados para CSV: {caminho_csv}\")\n",
    "    logging.info(\"Simulação de Carga concluída. Pronto para Modelagem/Deploy (TensorFlow/PyTorch).\")\n",
    "\n",
    "\n",
    "# --- 5. EXECUÇÃO PRINCIPAL ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Extração\n",
    "    dados_inmet = extrair_dados_inmet(CODIGO_ESTACAO_INMET, DATA_INICIO, DATA_FIM)\n",
    "    dados_ons = extrair_dados_ons_ccee('ONS')\n",
    "    dados_ccee = extrair_dados_ons_ccee('CCEE')\n",
    "\n",
    "    if dados_ons.empty or dados_ccee.empty:\n",
    "        logging.error(\"Extração simulada falhou. Verifique as funções de extração.\")\n",
    "    else:\n",
    "        # 2. Transformação (Criação do Big Data Unificado)\n",
    "        dataset_hpo = transformar_dados(dados_inmet, dados_ons, dados_ccee)\n",
    "        \n",
    "        # 3. Carga\n",
    "        carregar_dados(dataset_hpo, f\"dados_hpo_integrados_{DATA_FIM.strftime('%Y%m%d')}.csv\")\n",
    "\n",
    "        # Exibe as primeiras linhas do Big Data unificado\n",
    "        print(\"\\n--- Amostra do Dataset Integrado (Big Data) ---\")\n",
    "        print(dataset_hpo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72a9c157-9b38-408d-b154-8ac31a55a413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 15:41:46,564 - INFO - Iniciando leitura do arquivo integrado: dados_hpo_integrados_20250926.csv\n",
      "2025-09-29 15:41:46,575 - INFO - Leitura concluída. Dataset com 720 linhas.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Amostra do Big Data Integrado (Pronto para ML) ---\n",
      "            timestamp  carga_mw_subsistema  frequencia_hz  geracao_eolica_mw  \\\n",
      "0 2025-08-27 14:00:00                25000          60.00                500   \n",
      "1 2025-08-27 15:00:00                25001          60.01                501   \n",
      "2 2025-08-27 16:00:00                25002          60.02                502   \n",
      "3 2025-08-27 17:00:00                25003          60.03                503   \n",
      "4 2025-08-27 18:00:00                25004          60.04                504   \n",
      "\n",
      "   restricao_vazao  CHUVA  TEMP_BULB_SECO  carga_lag_24h  alerta_intermitente  \n",
      "0                1    2.0            24.0            NaN                    0  \n",
      "1                0    0.0            25.0            NaN                    0  \n",
      "2                0    1.0            26.0            NaN                    0  \n",
      "3                0    2.0            27.0            NaN                    0  \n",
      "4                0    0.0            28.0            NaN                    0  \n",
      "\n",
      "Tipo de dado da coluna 'timestamp' agora é: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- DEFINA O CAMINHO COMPLETO DO ARQUIVO AQUI ---\n",
    "# Este caminho DEVE apontar diretamente para o arquivo CSV.\n",
    "FILE_PATH = r\"C:\\Users\\lostj\\Documents\\Data\\projects\\Integrated Predictive System for Maximizing Operational Efficiency\\dados_projeto_hpo\\dados_hpo_integrados_20250926.csv\"\n",
    "\n",
    "def read_integrated_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lê o arquivo CSV unificado e realiza a conversão essencial de tipos de dados.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Caminho completo para o arquivo CSV integrado.\n",
    "\n",
    "    Returns:\n",
    "        Um DataFrame do Pandas com a coluna de timestamp convertida.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        logging.error(f\"Erro: Arquivo não encontrado no caminho: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    logging.info(f\"Iniciando leitura do arquivo integrado: {os.path.basename(file_path)}\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Leitura do CSV\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "        \n",
    "        # 2. Conversão de Tipos (Essencial para Séries Temporais)\n",
    "        # Converte a coluna 'timestamp' para o tipo datetime, crucial para a modelagem LSTM.\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "        \n",
    "        # Remove linhas com timestamp inválido, caso haja\n",
    "        df = df.dropna(subset=['timestamp'])\n",
    "\n",
    "        logging.info(f\"Leitura concluída. Dataset com {len(df)} linhas.\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ocorreu um erro ao processar o arquivo CSV: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# --- EXECUÇÃO PRINCIPAL ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    integrated_data = read_integrated_data(FILE_PATH)\n",
    "    \n",
    "    if not integrated_data.empty:\n",
    "        print(\"\\n--- Amostra do Big Data Integrado (Pronto para ML) ---\")\n",
    "        print(integrated_data.head())\n",
    "        \n",
    "        # Confirma que a coluna 'timestamp' foi corretamente convertida\n",
    "        print(f\"\\nTipo de dado da coluna 'timestamp' agora é: {integrated_data['timestamp'].dtype}\")\n",
    "        \n",
    "        # Próximo passo: Análise Exploratória de Dados (EDA) e Modelagem Preditiva."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c1f9da-34b0-4dff-b8c4-983504540fe6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a27aa544-82db-45a0-80c5-33b214792a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\lostj\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (1.75.1)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: pillow in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffd820aa-14f1-43e8-b436-40aa0b3a64df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.Jupyter detected...\n",
      "3 channel Terms of Service accepted\n",
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "LibMambaUnsatisfiableError: Encountered problems while solving:\n",
      "  - nothing provides bleach 1.5.0 needed by tensorboard-1.7.0-py35he025d50_1\n",
      "\n",
      "Could not solve for environment specs\n",
      "The following packages are incompatible\n",
      "\\u251c\\u2500 \u001b[32mpin on python 3.13.* =* *\u001b[0m is installable and it requires\n",
      "\\u2502  \\u2514\\u2500 \u001b[32mpython =3.13 *\u001b[0m, which can be installed;\n",
      "\\u2514\\u2500 \u001b[31mtensorflow =* *\u001b[0m is not installable because there are no viable options\n",
      "   \\u251c\\u2500 \u001b[31mtensorflow [1.10.0|1.9.0]\u001b[0m would require\n",
      "   \\u2502  \\u2514\\u2500 \u001b[31mpython =3.5 *\u001b[0m, which conflicts with any installable versions previously reported;\n",
      "   \\u251c\\u2500 \u001b[31mtensorflow [1.10.0|1.11.0|...|2.1.0]\u001b[0m would require\n",
      "   \\u2502  \\u2514\\u2500 \u001b[31mpython =3.6 *\u001b[0m, which conflicts with any installable versions previously reported;\n",
      "   \\u251c\\u2500 \u001b[31mtensorflow [1.13.1|1.14.0|...|2.9.1]\u001b[0m would require\n",
      "   \\u2502  \\u2514\\u2500 \u001b[31mpython =3.7 *\u001b[0m, which conflicts with any installable versions previously reported;\n",
      "   \\u251c\\u2500 \u001b[31mtensorflow [1.7.0|1.7.1|1.8.0]\u001b[0m would require\n",
      "   \\u2502  \\u2514\\u2500 \u001b[31mtensorboard [>=1.7.0,<1.8.0 *|>=1.8.0,<1.9.0 *]\u001b[0m, which requires\n",
      "   \\u2502     \\u2514\\u2500 \u001b[31mbleach ==1.5.0 *\u001b[0m, which does not exist (perhaps a missing channel);\n",
      "   \\u251c\\u2500 \u001b[31mtensorflow [2.10.0|2.18.1|2.8.2|2.9.1]\u001b[0m would require\n",
      "   \\u2502  \\u2514\\u2500 \u001b[31mpython [=3.10 *|>=3.10,<3.11.0a0 *]\u001b[0m, which conflicts with any installable versions previously reported;\n",
      "   \\u251c\\u2500 \u001b[31mtensorflow [2.10.0|2.3.0|...|2.9.1]\u001b[0m would require\n",
      "   \\u2502  \\u2514\\u2500 \u001b[31mpython =3.8 *\u001b[0m, which conflicts with any installable versions previously reported;\n",
      "   \\u251c\\u2500 \u001b[31mtensorflow [2.10.0|2.18.1|...|2.9.1]\u001b[0m would require\n",
      "   \\u2502  \\u2514\\u2500 \u001b[31mpython [=3.9 *|>=3.9,<3.10.0a0 *]\u001b[0m, which conflicts with any installable versions previously reported;\n",
      "   \\u251c\\u2500 \u001b[31mtensorflow 2.18.1\u001b[0m would require\n",
      "   \\u2502  \\u2514\\u2500 \u001b[31mpython >=3.11,<3.12.0a0 *\u001b[0m, which conflicts with any installable versions previously reported;\n",
      "   \\u2514\\u2500 \u001b[31mtensorflow 2.18.1\u001b[0m would require\n",
      "      \\u2514\\u2500 \u001b[31mpython >=3.12,<3.13.0a0 *\u001b[0m, which conflicts with any installable versions previously reported.\n",
      "\n",
      "Pins seem to be involved in the conflict. Currently pinned specs:\n",
      " - python=3.13\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ff21278-3b5f-4e92-8db0-a7ba539fda63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow[and-cuda] in c:\\users\\lostj\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (1.75.1)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (3.12.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\lostj\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (0.5.3)\n",
      "Collecting nvidia-cublas-cu12<13.0,>=12.5.3.2 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cublas_cu12-12.9.1.4-py3-none-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.9.79-py3-none-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvcc_cu12-12.9.86-py3-none-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.9.86-py3-none-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.9.79-py3-none-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12<10.0,>=9.3.0.75 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cudnn_cu12-9.13.1.26-py3-none-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cufft-cu12<12.0,>=11.2.3.61 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cufft_cu12-11.4.1.4-py3-none-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-curand-cu12<11.0,>=10.3.6.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_curand_cu12-10.3.10.19-py3-none-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12<12.0,>=11.6.3.83 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusolver_cu12-11.7.5.82-py3-none-win_amd64.whl.metadata (1.9 kB)\n",
      "Collecting nvidia-cusparse-cu12<13.0,>=12.5.1.3 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusparse_cu12-12.5.10.65-py3-none-win_amd64.whl.metadata (1.8 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflow[and-cuda] to determine which version is compatible with other requirements. This could take a while.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement nvidia-nccl-cu12<3.0,>=2.25.1; extra == \"and-cuda\" (from tensorflow[and-cuda]) (from versions: 0.0.1.dev5)\n",
      "ERROR: No matching distribution found for nvidia-nccl-cu12<3.0,>=2.25.1; extra == \"and-cuda\"\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c465b47a-0c92-4d84-8ac1-1d339823eeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a94da0d-55ac-42f5-90eb-c54b44333d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 15:43:05,240 - INFO - Dados prontos para LSTM. X_shape: (672, 24, 7), y_shape: (672,)\n",
      "2025-09-29 15:43:05,241 - INFO - Iniciando construção e treino do modelo LSTM.\n",
      "C:\\Users\\lostj\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0026 - val_loss: 5.5474e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 15:43:08,834 - INFO - Treinamento concluído.\n",
      "2025-09-29 15:43:08,840 - INFO - Iniciando a Simulação de Previsão e Otimização.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 15:43:09,022 - INFO - Previsão de Carga para 2025-09-26 14:00:00: 25690.88 MW\n",
      "2025-09-29 15:43:09,023 - WARNING - Carga prevista alta. Sugestão de Despacho (Otimizado): 800 MW.\n",
      "2025-09-29 15:43:09,023 - INFO - O modelo preditivo agora guia a Otimização da Curva Horária, respeitando as Restrições.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import logging\n",
    "import os\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- DEFINA O CAMINHO DO ARQUIVO ---\n",
    "# Use o caminho confirmado onde o seu CSV integrado está.\n",
    "FILE_PATH = r\"C:\\Users\\lostj\\Documents\\Data\\projects\\Integrated Predictive System for Maximizing Operational Efficiency\\dados_projeto_hpo\\dados_hpo_integrados_20250926.csv\"\n",
    "\n",
    "# Variáveis que o modelo preditivo irá utilizar\n",
    "FEATURES = [\n",
    "    'carga_mw_subsistema', 'frequencia_hz', 'geracao_eolica_mw',\n",
    "    'restricao_vazao', 'CHUVA', 'TEMP_BULB_SECO', 'carga_lag_24h'\n",
    "]\n",
    "TARGET = 'carga_mw_subsistema'  # O que queremos prever\n",
    "\n",
    "# Parâmetros de Série Temporal\n",
    "TIME_STEPS = 24  # Usar as últimas 24 horas para prever a próxima\n",
    "PREDICT_HORIZON = 1 # Prever a próxima hora\n",
    "\n",
    "def load_and_preprocess_for_lstm(file_path: str, features: list, target: str, time_steps: int):\n",
    "    \"\"\"Carrega, limpa, normaliza e transforma os dados em sequências LSTM.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "        df = df.dropna(subset=['timestamp']).set_index('timestamp').sort_index()\n",
    "\n",
    "        # 1. Seleção e Limpeza Final\n",
    "        df = df[features].dropna()\n",
    "        \n",
    "        # 2. Normalização (Essencial para Deep Learning)\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_data = scaler.fit_transform(df)\n",
    "        \n",
    "        # 3. Transformação em Sequências (Time-Series Formatting)\n",
    "        X, y = [], []\n",
    "        for i in range(len(scaled_data) - time_steps - PREDICT_HORIZON + 1):\n",
    "            # Sequência de entrada (24 horas)\n",
    "            X.append(scaled_data[i:(i + time_steps)])\n",
    "            # Valor alvo (a carga da hora seguinte)\n",
    "            target_index = df.columns.get_loc(target)\n",
    "            y.append(scaled_data[i + time_steps, target_index])\n",
    "            \n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        logging.info(f\"Dados prontos para LSTM. X_shape: {X.shape}, y_shape: {y.shape}\")\n",
    "        \n",
    "        # Guardar o scaler para desnormalizar as previsões futuras (crucial)\n",
    "        return X, y, scaler\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro na preparação dos dados para LSTM: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# --- 2. MODELAGEM PREDITIVA (LSTM) ---\n",
    "\n",
    "def create_and_train_lstm_model(X, y):\n",
    "    \"\"\"Cria e treina um modelo LSTM simples.\"\"\"\n",
    "    logging.info(\"Iniciando construção e treino do modelo LSTM.\")\n",
    "    \n",
    "    # Divisão simples em treino e teste (80/20)\n",
    "    train_size = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "    # Definição do Modelo (Inspirado no seu uso de TensorFlow/PyTorch)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(units=1)) # Apenas uma saída: a carga prevista\n",
    "    \n",
    "    # Compilação e Treino\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Treinamento com uma época rápida para simulação\n",
    "    model.fit(X_train, y_train, epochs=1, batch_size=1, verbose=1, validation_data=(X_test, y_test))\n",
    "    \n",
    "    logging.info(\"Treinamento concluído.\")\n",
    "    return model\n",
    "\n",
    "# --- 3. INTEGRAÇÃO E OTIMIZAÇÃO CONCEITUAL ---\n",
    "\n",
    "def conceptual_optimization(model, X_new, scaler):\n",
    "    \"\"\"\n",
    "    Simula a previsão e o passo conceitual para Otimização da Curva Horária.\n",
    "    Isto é o coração do HPO: usar a previsão para guiar a operação.\n",
    "    \"\"\"\n",
    "    logging.info(\"Iniciando a Simulação de Previsão e Otimização.\")\n",
    "    \n",
    "    # 1. Previsão\n",
    "    predicted_scaled = model.predict(X_new)\n",
    "    \n",
    "    # 2. Desnormalização da Previsão (Crucial)\n",
    "    # Criamos uma matriz temporária para desnormalizar apenas o valor da carga (TARGET)\n",
    "    dummy_array = np.zeros((len(predicted_scaled), len(FEATURES)))\n",
    "    target_index = FEATURES.index(TARGET)\n",
    "    dummy_array[:, target_index] = predicted_scaled.flatten()\n",
    "    \n",
    "    # Desnormaliza o valor previsto (agora está em MW)\n",
    "    predicted_mw = scaler.inverse_transform(dummy_array)[:, target_index]\n",
    "    \n",
    "    # 3. Ponto de Decisão (Otimização da Curva Horária)\n",
    "    forecast_time = pd.to_datetime(integrated_data.index[-1] + timedelta(hours=1))\n",
    "    \n",
    "    logging.info(f\"Previsão de Carga para {forecast_time}: {predicted_mw[0]:.2f} MW\")\n",
    "    \n",
    "    # ** Conceito de Otimização (Programação Linear): **\n",
    "    # Se a previsão for alta (acima de 25500 MW), o sistema precisa de mais estabilidade\n",
    "    PREDICTED_LOAD = predicted_mw[0]\n",
    "    MIN_HYDRO_REQUIRED = 500 # Geração mínima obrigatória (Restrição Operacional)\n",
    "    MAX_HYDRO_CAPACITY = 1200 # Capacidade máxima da hidrelétrica\n",
    "    \n",
    "    if PREDICTED_LOAD > 25500:\n",
    "        # A Otimização (algoritmo) sugeriria o despacho ideal:\n",
    "        SUGGESTED_DISPATCH = min(MAX_HYDRO_CAPACITY, MIN_HYDRO_REQUIRED + 300) \n",
    "        logging.warning(f\"Carga prevista alta. Sugestão de Despacho (Otimizado): {SUGGESTED_DISPATCH} MW.\")\n",
    "    else:\n",
    "        SUGGESTED_DISPATCH = MIN_HYDRO_REQUIRED\n",
    "        logging.info(f\"Carga prevista normal. Sugestão de Despacho (Otimizado): {SUGGESTED_DISPATCH} MW.\")\n",
    "        \n",
    "    logging.info(\"O modelo preditivo agora guia a Otimização da Curva Horária, respeitando as Restrições.\")\n",
    "\n",
    "\n",
    "# --- EXECUÇÃO PRINCIPAL ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X, y, scaler = load_and_preprocess_for_lstm(FILE_PATH, FEATURES, TARGET, TIME_STEPS)\n",
    "    \n",
    "    if X is not None:\n",
    "        # Treinamento do modelo\n",
    "        model = create_and_train_lstm_model(X, y)\n",
    "        \n",
    "        # Previsão para a próxima hora\n",
    "        # Pega a última sequência de tempo para fazer a previsão\n",
    "        X_new = X[-1].reshape(1, TIME_STEPS, len(FEATURES))\n",
    "        \n",
    "        # Simulação do HPO: Previsão + Otimização\n",
    "        integrated_data = pd.read_csv(FILE_PATH, low_memory=False)\n",
    "        integrated_data['timestamp'] = pd.to_datetime(integrated_data['timestamp'], errors='coerce')\n",
    "        integrated_data = integrated_data.dropna(subset=['timestamp']).set_index('timestamp').sort_index()\n",
    "\n",
    "        conceptual_optimization(model, X_new, scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500727cd-01f8-4f0a-af3f-87b8e1c6f3aa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61e06de0-e47c-4c22-9c03-91a35aa7ac4e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05f79b65-61ee-4931-b576-7fd8096b2d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 15:43:09,202 - INFO - Dados prontos para LSTM. X_shape: (672, 24, 7), y_shape: (672,)\n",
      "2025-09-29 15:43:09,202 - INFO - Iniciando construção e treino do modelo LSTM.\n",
      "C:\\Users\\lostj\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0026 - val_loss: 2.8667e-04\n",
      "Epoch 2/3\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.7231e-04 - val_loss: 4.4829e-04\n",
      "Epoch 3/3\n",
      "\u001b[1m537/537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 9.9311e-05 - val_loss: 1.8030e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 15:43:16,210 - INFO - Treinamento concluído.\n",
      "2025-09-29 15:43:16,210 - INFO - Iniciando Validação Rigorosa (Cálculo de RMSE).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 15:43:16,531 - INFO - RMSE (Root Mean Squared Error) no Test Set: 9.33 MW\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Validação: Previsão vs. Real (Amostra) ---\n",
      "   Real (MW)  Previsto (MW)  Erro Absoluto\n",
      "0    25585.0       25583.01           1.99\n",
      "1    25586.0       25583.87           2.13\n",
      "2    25587.0       25587.29           0.29\n",
      "3    25588.0       25588.52           0.52\n",
      "4    25589.0       25586.41           2.59\n",
      "5    25590.0       25585.52           4.48\n",
      "6    25591.0       25591.37           0.37\n",
      "7    25592.0       25589.44           2.56\n",
      "8    25593.0       25591.67           1.33\n",
      "9    25594.0       25592.28           1.72\n",
      "\n",
      "O RMSE de 9.33 MW indica a diferença média de erro de previsão no Test Set.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import logging\n",
    "import os\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- DEFINA O CAMINHO DO ARQUIVO ---\n",
    "FILE_PATH = r\"C:\\Users\\lostj\\Documents\\Data\\projects\\Integrated Predictive System for Maximizing Operational Efficiency\\dados_projeto_hpo\\dados_hpo_integrados_20250926.csv\"\n",
    "\n",
    "# Variáveis que o modelo preditivo irá utilizar\n",
    "FEATURES = [\n",
    "    'carga_mw_subsistema', 'frequencia_hz', 'geracao_eolica_mw',\n",
    "    'restricao_vazao', 'CHUVA', 'TEMP_BULB_SECO', 'carga_lag_24h'\n",
    "]\n",
    "TARGET = 'carga_mw_subsistema'  # O que queremos prever\n",
    "TIME_STEPS = 24  \n",
    "PREDICT_HORIZON = 1 \n",
    "\n",
    "# O scaler é um objeto de estado e precisa ser retornado para a desnormalização\n",
    "global SCALER_GLOBAL\n",
    "SCALER_GLOBAL = None\n",
    "\n",
    "\n",
    "# --- 1. PREPARAÇÃO DOS DADOS ---\n",
    "\n",
    "def load_and_preprocess_for_lstm(file_path: str, features: list, target: str, time_steps: int):\n",
    "    \"\"\"Carrega, limpa, normaliza e transforma os dados em sequências LSTM.\"\"\"\n",
    "    global SCALER_GLOBAL\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "        df = df.dropna(subset=['timestamp']).set_index('timestamp').sort_index()\n",
    "\n",
    "        df = df[features].dropna()\n",
    "        \n",
    "        # 2. Normalização (Escalonamento)\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_data = scaler.fit_transform(df)\n",
    "        SCALER_GLOBAL = scaler # Salva o scaler globalmente\n",
    "        \n",
    "        # 3. Transformação em Sequências\n",
    "        X, y = [], []\n",
    "        for i in range(len(scaled_data) - time_steps - PREDICT_HORIZON + 1):\n",
    "            X.append(scaled_data[i:(i + time_steps)])\n",
    "            target_index = df.columns.get_loc(target)\n",
    "            y.append(scaled_data[i + time_steps, target_index])\n",
    "            \n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        logging.info(f\"Dados prontos para LSTM. X_shape: {X.shape}, y_shape: {y.shape}\")\n",
    "        \n",
    "        # 4. Divisão Treino/Teste\n",
    "        train_size = int(len(X) * 0.8)\n",
    "        X_train, X_test = X[:train_size], X[train_size:]\n",
    "        y_train, y_test = y[:train_size], y[train_size:]\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test, df # Retorna o DataFrame original para desnormalizar índices\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro na preparação dos dados para LSTM: {e}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "\n",
    "# --- 2. MODELAGEM E TREINO ---\n",
    "\n",
    "def create_and_train_lstm_model(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Cria e treina um modelo LSTM.\"\"\"\n",
    "    logging.info(\"Iniciando construção e treino do modelo LSTM.\")\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(units=1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=3, batch_size=1, verbose=1, validation_data=(X_test, y_test))\n",
    "    \n",
    "    logging.info(\"Treinamento concluído.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# --- 3. VALIDAÇÃO RIGOROSA ---\n",
    "\n",
    "def rigorous_validation(model, X_test, y_test, df_original):\n",
    "    \"\"\"Calcula RMSE e compara Previsões vs. Valores Reais em MW.\"\"\"\n",
    "    logging.info(\"Iniciando Validação Rigorosa (Cálculo de RMSE).\")\n",
    "    \n",
    "    # 1. Previsão\n",
    "    predicted_scaled = model.predict(X_test)\n",
    "    \n",
    "    # 2. Desnormalização (Voltar para MW)\n",
    "    global SCALER_GLOBAL\n",
    "    if SCALER_GLOBAL is None:\n",
    "        logging.error(\"Scaler não encontrado. Não é possível desnormalizar.\")\n",
    "        return\n",
    "\n",
    "    target_index = FEATURES.index(TARGET)\n",
    "    \n",
    "    # Função auxiliar para desnormalizar o target\n",
    "    def inverse_transform_target(scaled_values):\n",
    "        # Cria um array dummy com zeros e coloca os valores scaled na coluna do target\n",
    "        dummy_array = np.zeros((len(scaled_values), len(FEATURES)))\n",
    "        dummy_array[:, target_index] = scaled_values.flatten()\n",
    "        # Desnormaliza o array completo e pega apenas a coluna do target\n",
    "        return SCALER_GLOBAL.inverse_transform(dummy_array)[:, target_index]\n",
    "\n",
    "    y_predicted_mw = inverse_transform_target(predicted_scaled)\n",
    "    y_test_mw = inverse_transform_target(y_test)\n",
    "    \n",
    "    # 3. Cálculo do RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_mw, y_predicted_mw))\n",
    "    \n",
    "    logging.info(f\"RMSE (Root Mean Squared Error) no Test Set: {rmse:.2f} MW\")\n",
    "\n",
    "    # 4. Análise de Comparação (Visualização de Desempenho)\n",
    "    validation_df = pd.DataFrame({\n",
    "        'Real (MW)': y_test_mw,\n",
    "        'Previsto (MW)': y_predicted_mw,\n",
    "        'Erro Absoluto': np.abs(y_test_mw - y_predicted_mw)\n",
    "    })\n",
    "    \n",
    "    print(\"\\n--- Validação: Previsão vs. Real (Amostra) ---\")\n",
    "    print(validation_df.head(10).round(2))\n",
    "    print(f\"\\nO RMSE de {rmse:.2f} MW indica a diferença média de erro de previsão no Test Set.\")\n",
    "\n",
    "\n",
    "# --- EXECUÇÃO PRINCIPAL ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X_train, X_test, y_train, y_test, df_original = load_and_preprocess_for_lstm(FILE_PATH, FEATURES, TARGET, TIME_STEPS)\n",
    "    \n",
    "    if X_train is not None:\n",
    "        model = create_and_train_lstm_model(X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        # Execução da Validação Rigorosa\n",
    "        rigorous_validation(model, X_test, y_test, df_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca198b5-edd3-441d-a8df-4630314debf1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3426cf5a-56fa-4e07-8b40-6ac095365ef8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "314f20b1-9eb8-4bb8-9f40-dff23cd3c04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pulp in c:\\users\\lostj\\anaconda3\\lib\\site-packages (3.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pulp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e27f375-b25c-4f86-8ab0-974d98c374fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: conda-script.py [-h] [-v] [--no-plugins] [-V] COMMAND ...\n",
      "conda-script.py: error: argument COMMAND: invalid choice: 'all' (choose from activate, build, clean, commands, compare, config, content-trust, convert, create, deactivate, debug, develop, doctor, env, export, index, info, init, inspect, install, list, metapackage, notices, pack, package, remove, rename, render, repo, repoquery, run, search, server, skeleton, token, tos, uninstall, update, upgrade)\n"
     ]
    }
   ],
   "source": [
    "conda all -c conda-forge pulp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65dce903-44cf-4a5f-b509-b3d28b5d2922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 15:43:21,372 - INFO - Carga Total Prevista: 25700.21 MW\n",
      "2025-09-29 15:43:21,373 - INFO - Geração Intermitente Prevista: 24500.00 MW\n",
      "2025-09-29 15:43:21,374 - INFO - Demanda Remanescente para Hidrelétrica: 1200.21 MW\n",
      "2025-09-29 15:43:21,374 - INFO - \n",
      "--- Iniciando Otimização da Curva Horária (PuLP) ---\n",
      "2025-09-29 15:43:21,376 - INFO - Restrição Ativa: G_hidro deve ser entre 400.0 MW e 1500.0 MW.\n",
      "2025-09-29 15:43:21,407 - WARNING - SUGESTÃO HPO (OTIMIZADA): Despachar 1200.21 MW (Hidro)\n",
      "2025-09-29 15:43:21,408 - INFO - O Despacho garante um erro de atendimento mínimo de: 0.00 MW\n",
      "2025-09-29 15:43:21,408 - INFO - Restrição Mínima Obrigatória (400.0 MW) respeitada.\n",
      "2025-09-29 15:43:21,409 - INFO - \n",
      "[MLOps / INTEGRAÇÃO]: O valor de Despacho Otimizado (1200.21 MW) é enviado para o sistema operacional da usina em tempo real.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pulp import LpProblem, LpMinimize, LpVariable, LpStatus, value\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Supondo que você já executou a instalação: pip install pulp\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- CONFIGURAÇÕES DO SISTEMA HPO ---\n",
    "FILE_PATH = r\"C:\\Users\\lostj\\Documents\\Data\\projects\\Integrated Predictive System for Maximizing Operational Efficiency\\dados_projeto_hpo\\dados_hpo_integrados_20250926.csv\"\n",
    "FEATURES = ['carga_mw_subsistema', 'frequencia_hz', 'geracao_eolica_mw',\n",
    "            'restricao_vazao', 'CHUVA', 'TEMP_BULB_SECO', 'carga_lag_24h']\n",
    "TARGET = 'carga_mw_subsistema' \n",
    "TIME_STEPS = 24  \n",
    "PREDICT_HORIZON = 1 \n",
    "SCALER_GLOBAL = None\n",
    "\n",
    "# Parâmetros Operacionais (Restrições)\n",
    "MIN_GERACAO_OBRIGATORIA = 400.0  # MW (Restrição Ambiental/Operativa)\n",
    "MAX_GERACAO_CAPACIDADE = 1500.0  # MW (Capacidade Máxima da Usina)\n",
    "\n",
    "\n",
    "# --- FUNÇÕES LSTM (Adaptadas do Passo Anterior para Reuso) ---\n",
    "\n",
    "# [Código das funções load_and_preprocess_for_lstm e create_and_train_lstm_model omitido por concisão, \n",
    "# mas estas são as funções que fornecem a PREVISÃO (INPUT)]\n",
    "\n",
    "# NOTA: Para rodar este script, você precisa incluir as funções load_and_preprocess_for_lstm, \n",
    "# create_and_train_lstm_model e suas dependências (rigorous_validation) do passo anterior.\n",
    "\n",
    "# A função de Otimização é a novidade:\n",
    "def optimization_dispatch(carga_prevista_mw: float, geracao_intermitente_prevista: float):\n",
    "    \"\"\"\n",
    "    Define a Geração Hidrelétrica (G_hidro) ideal através de Programação Linear,\n",
    "    minimizando o erro de atendimento à carga e respeitando restrições.\n",
    "    \"\"\"\n",
    "    logging.info(\"\\n--- Iniciando Otimização da Curva Horária (PuLP) ---\")\n",
    "    \n",
    "    # 1. Variáveis do Problema\n",
    "    # Criar o modelo de minimização\n",
    "    model = LpProblem(\"Otimizacao_Despacho_Hidreletrica\", LpMinimize)\n",
    "    \n",
    "    # Variável de Decisão: Geração da Hidrelétrica (contínua)\n",
    "    # A geração deve ser ≥ MIN_GERACAO_OBRIGATORIA e ≤ MAX_GERACAO_CAPACIDADE\n",
    "    G_hidro = LpVariable(\"G_hidro\", \n",
    "                         lowBound=MIN_GERACAO_OBRIGATORIA, \n",
    "                         upBound=MAX_GERACAO_CAPACIDADE, \n",
    "                         cat='Continuous')\n",
    "    \n",
    "    # 2. Função Objetivo\n",
    "    # Objetivo: Minimizar a diferença (erro absoluto) entre a Carga Prevista\n",
    "    # e a Geração Total (Hidro + Intermitentes).\n",
    "    \n",
    "    # NOTA: Usamos a variável de erro 'delta' para linearizar o erro absoluto: |A - B| = delta\n",
    "    delta_positivo = LpVariable(\"delta_pos\", lowBound=0)\n",
    "    delta_negativo = LpVariable(\"delta_neg\", lowBound=0)\n",
    "    \n",
    "    # Função Objetivo: Minimizar a soma dos desvios (erro)\n",
    "    model += delta_positivo + delta_negativo, \"Minimizar_Erro_Despacho\"\n",
    "    \n",
    "    # 3. Restrição Principal (Equilíbrio de Carga)\n",
    "    # Carga Prevista - Geração Total = delta_positivo - delta_negativo\n",
    "    geracao_total = G_hidro + geracao_intermitente_prevista\n",
    "    model += (carga_prevista_mw - geracao_total) == (delta_positivo - delta_negativo), \"Equilibrio_Carga\"\n",
    "    \n",
    "    # Restrição Operacional de Vazão (Já embutida no lowBound de G_hidro)\n",
    "    logging.info(f\"Restrição Ativa: G_hidro deve ser entre {MIN_GERACAO_OBRIGATORIA} MW e {MAX_GERACAO_CAPACIDADE} MW.\")\n",
    "    \n",
    "    # 4. Solução\n",
    "    model.solve()\n",
    "    \n",
    "    # 5. Análise de Resultados\n",
    "    if LpStatus[model.status] == \"Optimal\":\n",
    "        despacho_otimizado = value(G_hidro)\n",
    "        erro_final = value(delta_positivo + delta_negativo)\n",
    "        \n",
    "        logging.warning(f\"SUGESTÃO HPO (OTIMIZADA): Despachar {despacho_otimizado:.2f} MW (Hidro)\")\n",
    "        logging.info(f\"O Despacho garante um erro de atendimento mínimo de: {erro_final:.2f} MW\")\n",
    "        logging.info(f\"Restrição Mínima Obrigatória ({MIN_GERACAO_OBRIGATORIA} MW) respeitada.\")\n",
    "        return despacho_otimizado\n",
    "    else:\n",
    "        logging.error(\"Otimização falhou. Verificar se as restrições são viáveis.\")\n",
    "        return None\n",
    "\n",
    "# --- EXECUÇÃO PRINCIPAL DA OTIMIZAÇÃO ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Passo 1: Configurar a Previsão (Inputs) ---\n",
    "    \n",
    "    # Usaremos valores simulados do resultado do LSTM (Seu resultado de 25700.21 MW)\n",
    "    CARGA_PREVISTA_MW = 25700.21 \n",
    "    \n",
    "    # A Geração Eólica/Solar Prevista (valor que o seu modelo de Gêmeo Digital/LSTM também preveria)\n",
    "    # Vamos simular uma geração intermitente de 24000 MW (valor alto, exigindo pouca hidro)\n",
    "    GERACAO_INTERMITENTE_PREVISTA = 24500.0 \n",
    "    \n",
    "    # Demanda remanescente que a Hidro precisa cobrir:\n",
    "    DEMANDA_REMANESCENTE = CARGA_PREVISTA_MW - GERACAO_INTERMITENTE_PREVISTA\n",
    "    \n",
    "    logging.info(f\"Carga Total Prevista: {CARGA_PREVISTA_MW:.2f} MW\")\n",
    "    logging.info(f\"Geração Intermitente Prevista: {GERACAO_INTERMITENTE_PREVISTA:.2f} MW\")\n",
    "    logging.info(f\"Demanda Remanescente para Hidrelétrica: {DEMANDA_REMANESCENTE:.2f} MW\")\n",
    "    \n",
    "    # --- Passo 2: Executar a Otimização ---\n",
    "    \n",
    "    # Chamar a função de otimização\n",
    "    despacho_final = optimization_dispatch(CARGA_PREVISTA_MW, GERACAO_INTERMITENTE_PREVISTA)\n",
    "    \n",
    "    # --- Passo 3: MLOps Conceitual ---\n",
    "    if despacho_final is not None:\n",
    "        logging.info(f\"\\n[MLOps / INTEGRAÇÃO]: O valor de Despacho Otimizado ({despacho_final:.2f} MW) é enviado para o sistema operacional da usina em tempo real.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4509ea8c-6907-4ae9-b398-55736b55dd88",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f427585-8143-4dd4-8aab-58e50e12a2ab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be9ae06e-6460-4b99-a8e3-bd80c0516f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 15:43:21,474 - INFO - \n",
      "--- SIMULAÇÃO DO DEPLOY E INFERÊNCIA EM TEMPO REAL ---\n",
      "2025-09-29 15:43:21,500 - WARNING - SUCESSO MLOPS: O Sistema de Despacho recebeu o valor 1200.00 MW via API de Inferência.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from pulp import LpProblem, LpMinimize, LpVariable, LpStatus, value\n",
    "import logging\n",
    "import os\n",
    "import joblib # Usado para salvar e carregar o scaler (prática comum em MLOps)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- CONFIGURAÇÕES DE PATHS E MODELO (PARA SERVIÇO) ---\n",
    "\n",
    "# O caminho onde o modelo final será salvo\n",
    "MODEL_DIR = \"hpo_model_deploy\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_FILENAME = os.path.join(MODEL_DIR, \"lstm_hpo_model.h5\")\n",
    "SCALER_FILENAME = os.path.join(MODEL_DIR, \"scaler_hpo.pkl\")\n",
    "\n",
    "# Parâmetros Operacionais (Importantes para a Otimização)\n",
    "MIN_GERACAO_OBRIGATORIA = 400.0  # MW\n",
    "MAX_GERACAO_CAPACIDADE = 1500.0  # MW\n",
    "\n",
    "# Variáveis (Devem ser iguais às usadas no treinamento)\n",
    "FEATURES = ['carga_mw_subsistema', 'frequencia_hz', 'geracao_eolica_mw',\n",
    "            'restricao_vazao', 'CHUVA', 'TEMP_BULB_SECO', 'carga_lag_24h']\n",
    "TARGET = 'carga_mw_subsistema' \n",
    "TIME_STEPS = 24  \n",
    "\n",
    "\n",
    "# --- 1. FUNÇÕES ESSENCIAIS DE OTIMIZAÇÃO E PREVISÃO (CÓPIA) ---\n",
    "\n",
    "def optimization_dispatch(carga_prevista_mw: float, geracao_intermitente_prevista: float) -> float:\n",
    "    \"\"\"Função de Otimização (PuLP) - Retorna o Despacho Ideal.\"\"\"\n",
    "    model = LpProblem(\"Otimizacao_Despacho_Hidreletrica\", LpMinimize)\n",
    "    \n",
    "    G_hidro = LpVariable(\"G_hidro\", lowBound=MIN_GERACAO_OBRIGATORIA, upBound=MAX_GERACAO_CAPACIDADE, cat='Continuous')\n",
    "    delta_positivo = LpVariable(\"delta_pos\", lowBound=0)\n",
    "    delta_negativo = LpVariable(\"delta_neg\", lowBound=0)\n",
    "    \n",
    "    model += delta_positivo + delta_negativo, \"Minimizar_Erro_Despacho\"\n",
    "    geracao_total = G_hidro + geracao_intermitente_prevista\n",
    "    model += (carga_prevista_mw - geracao_total) == (delta_positivo - delta_negativo), \"Equilibrio_Carga\"\n",
    "    \n",
    "    model.solve()\n",
    "    \n",
    "    if LpStatus[model.status] == \"Optimal\":\n",
    "        return value(G_hidro)\n",
    "    else:\n",
    "        logging.error(\"Otimização falhou. Retornando mínimo obrigatório por segurança.\")\n",
    "        return MIN_GERACAO_OBRIGATORIA\n",
    "\n",
    "def inverse_transform_target(scaled_value, scaler, features_list, target_name):\n",
    "    \"\"\"Desnormaliza o valor previsto para a escala MW real.\"\"\"\n",
    "    target_index = features_list.index(target_name)\n",
    "    dummy_array = np.zeros((1, len(features_list)))\n",
    "    dummy_array[:, target_index] = scaled_value.flatten()\n",
    "    return scaler.inverse_transform(dummy_array)[:, target_index][0]\n",
    "\n",
    "\n",
    "# --- 2. FUNÇÃO DE SERVIÇO (API DE INFERÊNCIA) ---\n",
    "\n",
    "def predict_and_optimize_realtime(new_data_sequence: np.ndarray, model, scaler):\n",
    "    \"\"\"\n",
    "    Simula a API que roda o modelo em tempo real e chama a otimização.\n",
    "    \n",
    "    Args:\n",
    "        new_data_sequence: Últimas 24h de dados operacionais (já normalizados e formatados).\n",
    "    \"\"\"\n",
    "    logging.info(\"\\n[API] Recebendo sequência de 24h para inferência.\")\n",
    "    \n",
    "    # A sequência de entrada deve ter o shape (1, 24, 7)\n",
    "    if new_data_sequence.shape != (1, TIME_STEPS, len(FEATURES)):\n",
    "        logging.error(f\"Formato de entrada incorreto. Esperado (1, {TIME_STEPS}, {len(FEATURES)})\")\n",
    "        return None\n",
    "    \n",
    "    # 1. Previsão da Carga Futura (P)\n",
    "    predicted_scaled = model.predict(new_data_sequence)[0] # Resultado em escala normalizada\n",
    "    carga_prevista_mw = inverse_transform_target(predicted_scaled, scaler, FEATURES, TARGET)\n",
    "    \n",
    "    logging.info(f\"PREVISÃO LSTM: Carga Futura estimada em {carga_prevista_mw:.2f} MW.\")\n",
    "    \n",
    "    # 2. Extração da Geração Intermitente Prevista\n",
    "    # No mundo real, a Geração Intermitente viria de outro modelo ou previsão de mercado.\n",
    "    # Aqui, simulamos que a geração intermitente é a última da sequência de entrada (última hora da janela)\n",
    "    # do seu conjunto de features.\n",
    "    intermitente_scaled = new_data_sequence[0, -1, FEATURES.index('geracao_eolica_mw')]\n",
    "    \n",
    "    # Desnormalizamos APENAS a intermitente para ser usada na Otimização\n",
    "    dummy_array = np.zeros((1, len(FEATURES)))\n",
    "    dummy_array[:, FEATURES.index('geracao_eolica_mw')] = intermitente_scaled\n",
    "    geracao_intermitente_prevista = scaler.inverse_transform(dummy_array)[:, FEATURES.index('geracao_eolica_mw')][0]\n",
    "    \n",
    "    \n",
    "    # 3. Otimização do Despacho (O)\n",
    "    despacho_otimizado = optimization_dispatch(carga_prevista_mw, geracao_intermitente_prevista)\n",
    "    \n",
    "    if despacho_otimizado is not None:\n",
    "        logging.warning(f\"[RESULTADO FINAL ENVIADO À USINA]: Despachar {despacho_otimizado:.2f} MW (Hidro) para a próxima hora.\")\n",
    "        return {\"despacho_otimizado\": despacho_otimizado}\n",
    "    return None\n",
    "\n",
    "\n",
    "# --- 3. EXECUÇÃO PRINCIPAL E DEPLOY ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Passo 1: SERIALIZAR O MODELO E O SCALER ---\n",
    "    \n",
    "    # (Requer re-execução das etapas de load e train para obter os objetos)\n",
    "    # NOTA: Assumimos que você já possui os objetos 'model' e 'SCALER_GLOBAL' do passo anterior.\n",
    "    \n",
    "    # SIMULAÇÃO DA SERIALIZAÇÃO (Se você tivesse o objeto 'model' e 'SCALER_GLOBAL')\n",
    "    \n",
    "    # CÓDIGO CONCEITUAL:\n",
    "    # model.save(MODEL_FILENAME)\n",
    "    # joblib.dump(SCALER_GLOBAL, SCALER_FILENAME)\n",
    "    # logging.info(f\"Modelo e Scaler salvos em {MODEL_DIR}\")\n",
    "    \n",
    "    # Para prosseguir, usaremos objetos fictícios:\n",
    "    \n",
    "    # Simulação: Carregando o modelo (em MLOps real, o serviço faria isso)\n",
    "    \n",
    "    # Criamos um modelo fictício para a inferência:\n",
    "    X_ficticio = np.random.rand(1, TIME_STEPS, len(FEATURES))\n",
    "    \n",
    "    # --- Fim da Simulação ---\n",
    "    \n",
    "    logging.info(\"\\n--- SIMULAÇÃO DO DEPLOY E INFERÊNCIA EM TEMPO REAL ---\")\n",
    "    \n",
    "    # Na prática MLOps, a API carregaria o modelo antes de receber a primeira requisição.\n",
    "    try:\n",
    "        # Tenta carregar o modelo e o scaler (Se você rodou o código de save)\n",
    "        # model_loaded = load_model(MODEL_FILENAME)\n",
    "        # scaler_loaded = joblib.load(SCALER_FILENAME)\n",
    "        \n",
    "        # Como não salvamos de fato, usamos a instância do modelo treinado anteriormente (model)\n",
    "        # e o SCALER_GLOBAL (que assumimos estar carregado em uma execução prévia)\n",
    "        \n",
    "        # Chamada da API com novos dados (Simulamos 24h de dados recém-coletados)\n",
    "        # 24h de dados padronizados (0 a 1)\n",
    "        new_data_for_prediction = np.random.rand(1, TIME_STEPS, len(FEATURES)) \n",
    "        \n",
    "        # Para demonstração, o scaler_loaded será uma instância MinMaxScaler vazia (simplificação)\n",
    "        scaler_loaded = MinMaxScaler(feature_range=(0, 1))\n",
    "        \n",
    "        # NOTE: Aqui precisaria do modelo treinado. \n",
    "        # Como o script é modular, vamos simular o resultado da previsão para focar no fluxo MLOps.\n",
    "        \n",
    "        # SIMULAÇÃO DO RESULTADO DA PREVISÃO:\n",
    "        SIMULATED_PREDICTION_MW = 25800.0  # Nova carga prevista\n",
    "        SIMULATED_INTERMITENTE = 24600.0  # Nova intermitente prevista\n",
    "        \n",
    "        despacho = optimization_dispatch(SIMULATED_PREDICTION_MW, SIMULATED_INTERMITENTE)\n",
    "        \n",
    "        logging.warning(f\"SUCESSO MLOPS: O Sistema de Despacho recebeu o valor {despacho:.2f} MW via API de Inferência.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Falha na simulação de carga da API (MLOps): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d29a2b-f9db-4c44-8fa8-d8c0a504e12a",
   "metadata": {},
   "source": [
    "## Plano de Ação Final: Visualização, Aprimoramento e Documentação MLOps (HPO)\n",
    "\n",
    "### 1. Visualização Operacional (Monitoramento em Tempo Real)\n",
    "\n",
    "A visualização é a interface que garante a confiança e a adoção do operador do ONS. O dashboard deve se concentrar em mostrar o valor da **Previsão** e da **Otimização**.\n",
    "\n",
    "| Métrica Essencial | Dashboard (Visão Operacional) | Objetivo no Projeto HPO |\n",
    "| :--- | :--- | :--- |\n",
    "| **Geração Otimizada vs. Realizada** | **Curva Horária de Despacho (Gráfico de Linha):** Mostrar a **Sugestão Otimizada (PuLP)** *vs.* o valor que a usina **Realmente Despachou**. | Monitorar a adesão à Curva Otimizada e identificar falhas de integração ou operacionais. |\n",
    "| **Desvio de Carga ($\\Delta$ Carga)** | **KPI de RMSE Recente:** Exibir o **RMSE** calculado nas últimas 24h. | Medir a confiança do modelo. Se o RMSE aumentar drasticamente, aciona um alerta para re-treino. |\n",
    "| **Estabilidade do Sistema** | **Indicador de Frequência e Tensão (Semaforização):** Mostrar `frequencia_hz` em tempo real e sinalizar em vermelho/amarelo quando o modelo estiver operando próximo aos limites críticos. | Mitigar os impactos das variações na frequência e tensão. |\n",
    "| **Restrições Ambientais** | **KPI:** Geração Mínima Obrigatória. | Mostrar se o valor de **Despacho Otimizado** está violando a **Restrição Mínima Obrigatória** (a validação do PuLP). |\n",
    "\n",
    "### 2. Aprimoramento do Modelo (Hyperparameter Tuning - Conceitual)\n",
    "\n",
    "O objetivo é passar de um RMSE de $16.82 \\text{ MW}$ para um nível ainda mais baixo, usando a técnica de *Hyperparameter Tuning*.\n",
    "\n",
    "**Plano de Refinamento (Simulação com Keras Tuner/Optuna):**\n",
    "\n",
    "1.  **Objetivo:** Reduzir o **RMSE** no conjunto de teste.\n",
    "2.  **Parâmetros a Otimizar (Tuning):**\n",
    "    * **`TIME_STEPS` (Janela de Tempo):** Otimizar se 24h ou 48h de dados fornecem um contexto melhor para prever a próxima hora.\n",
    "    * **`LSTM Units` (Tamanho da Camada):** Otimizar o número de neurônios (e.g., de 50 para 64, 100, etc.) para encontrar o equilíbrio entre a complexidade e o risco de *overfitting*.\n",
    "    * **`Learning Rate` (Taxa de Aprendizado):** Otimizar a velocidade com que o modelo ajusta seus pesos durante o treinamento.\n",
    "3.  **Processo:** Executar o *Tuning* (por exemplo, com validação cruzada *Time-Series*) para identificar a **melhor combinação de hiperparâmetros** que resulte no menor RMSE no conjunto de dados não vistos.\n",
    "\n",
    "### 3. Documentação MLOps e Pipeline CI/CD\n",
    "\n",
    "Esta documentação garante a sustentabilidade e a confiabilidade do **Sistema Preditivo Integrado** ao longo do tempo.\n",
    "\n",
    "| Componente MLOps | Descrição e Ação (Baseado em seus Habilidades) |\n",
    "| :--- | :--- |\n",
    "| **Gatilho de Retreinamento (CI/CD)** | O modelo deve ser retreinado automaticamente quando: 1) Uma **nova semana** de dados do SIN estiver disponível. 2) O **RMSE no monitoramento ao vivo** exceder um limite crítico (e.g., $50 \\text{ MW}$). |\n",
    "| **Pipeline de Teste Automatizado** | Antes do *Deploy*: Executar testes de **Sanidade de Dados** (verificar se `geracao_eolica_mw` é não-negativo) e testes de **Performance do Modelo** (confirmar que o novo RMSE é $\\le 18 \\text{ MW}$). |\n",
    "| **Deploy (TensorFlow Serving)** | O modelo LSTM treinado é serializado (`model.save()`) e servido em um container Docker, garantindo que o sistema de operação possa acessá-lo via **endpoint HTTP** para inferência em tempo real. |\n",
    "| **Rollback** | Em caso de falha de comunicação ou aumento repentino e inesperado do erro de previsão (monitoramento), o sistema deve automaticamente reverter para a versão anterior (estável) do modelo. |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
